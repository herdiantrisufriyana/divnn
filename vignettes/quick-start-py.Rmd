---
title: "DeepInsight Visible Neural Network: Quick Start divnn python"
author:
  - name: Herdiantri Sufriyana
    affiliation:
    - &gibi Graduate Institute of Biomedical Informatics, College of Medical
      Science and Technology, Taipei Medical University, Taipei, Taiwan
    - Department of Medical Physiology, College of Medicine, University of
      Nahdlatul Ulama Surabaya, Surabaya, Indonesia
    email: herdiantrisufriyana@unusa.ac.id
  - name: Yu-Wei Wu
    affiliation:
    - *gibi
    - &tmuh Clinical Big Data Research Center, Taipei Medical University
      Hospital, Taipei, Taiwan
  - name: Emily Chia-Yu Su
    affiliation:
    - *gibi
    - *tmuh
    - Research Center for Artificial Intelligence in Medicine, Taipei Medical
      University, Taipei, Taiwan
package: divnn
abstract: >
  This vignette explains how to use this module using simulated data. However,
  reader may need to read another vignette to apply the DeepInsight Visible
  Neural Network (DI-VNN) model based on the original works of DeepInsight and
  VNN from Alok Sharma and Michael Ku Yu, respectively.
output:
  BiocStyle::html_document:
    toc_float: true
vignette: >
  %\VignetteIndexEntry{Quick Start}
  %\VignetteEngine{knitr::knitr}
  %\VignetteEncoding{UTF-8}
---




# Install and import

```{r Load reticulate, include=FALSE}
library(reticulate)
```

You can install this module using pip install git+. Then import this module as
shown below.

```{python Showing install and import this module, eval=FALSE, include=TRUE}
import os
os.system('pip install git+https://github.com/herdiantrisufriyana/divnn')

from divnn import utils, TidySet, generator
from divnn.ExpressionSet import exprs, notes
```

Several modules are needed to load explicitly since training and the other
functions are not included in this module. For simplicity, code to turn off your
GPU is also provided below.

```{python Showing load modules, eval=FALSE, include=TRUE}
import os
import pickle
import pandas as pd
import numpy as np
import regex as re
import math
os.environ['CUDA_VISIBLE_DEVICES']='-1'
from tensorflow import keras
from tensorflow.keras.models import model_from_json
```

```{python Load modules, include=FALSE}
from divnn import utils, TidySet, generator
from divnn.ExpressionSet import exprs, pData, fData, notes
import os
import pickle
import pandas as pd
import numpy as np
import regex as re
import math
os.environ['CUDA_VISIBLE_DEVICES']='-1'
from tensorflow import keras
from tensorflow.keras.models import model_from_json
```

```{r Load packages in R, include=FALSE}
library(divnn)
library(tidyverse)
library(BiocGenerics)
library(Biobase)
library(pbapply)
library(matrixStats)
```


# Load simulated data

Load simulated data using this code.

```{python Create input example, echo=TRUE}
input=utils.example()
```

The first input is a instance-feature value pandas data frame with rows for
instances and columns for features. All rows in value should have names. All
values should be floating numbers.

```{r Create the example in R, include=FALSE}
input=py$input %>% lapply(py_to_r)
```

```{r echo=FALSE}
input$value %>%
  cbind(data.frame(outcome=input$outcome)) %>%
  group_by(outcome) %>%
  summarize_all(function(x)paste(round(mean(x),2),'Â±',round(sd(x),2))) %>%
  gather(attribute,value,-outcome) %>%
  rbind(
    table(input$outcome) %>%
      as.data.frame() %>%
      rename(outcome=Var1,value=Freq) %>%
      mutate(outcome=as.double(outcome)-1) %>%
      mutate(attribute='outcome') %>%
      select(outcome,attribute,value)
  ) %>%
  mutate(outcome=paste0('outcome_',outcome)) %>%
  spread(outcome,value) %>%
  knitr::kable(
    format='html'
    ,caption='Summary of instance-feature value data frame'
  ) %>%
  kableExtra::kable_styling(full_width=T)
```

The second input is and outcome binary integers as a single-column pandas data
frame with the same rows as the instances. The row numbers, the names, and the
order of outcome should be the same with those of value. Value  of 0 and 1
should refer to non-event and event outcome, respectively.

```{python Outcome vector, echo=FALSE}
print(input['outcome'])
```

The third input is a similarity pandas data frame of floating numbers containing
feature-feature similarity measures.

```{r echo=FALSE}
input$similarity %>%
  knitr::kable(format='html',caption='Feature similarity matrix') %>%
  kableExtra::kable_styling(full_width=T)
```

The fourth input is a feature three-dimensional pandas data frame of floating
numbers with rows for features and three columns for three dimensions where the
features are mapped onto.

```{r echo=FALSE}
input$mapping %>%
  as.data.frame() %>%
  rename_all(function(x)str_replace_all(x,'V','dimension ')) %>%
  knitr::kable(format='html',caption='Feature three-dimensional mapping matrix') %>%
  kableExtra::kable_styling(full_width=T)
```

The fifth input is an ontology pandas data frame with rows for ontologies and
four columns for source, target, similarity, and relation. Feature (source)-
ontology (target) relation should be annotated as 'feature', while ontology-
ontology relation should be annotated as 'is_a'. To differentiate between
feature and ontology names, a prefix of 'ONT:' precedes an ontology name. All
columns except similarity in ontology should be characters. Similarity
(a numeric) is a minimum threshold by which either features or ontologies
(source) belong to an ontology (target).

```{r echo=FALSE}
input$ontology %>%
  knitr::kable(format='html',caption='Ontology data frame') %>%
  kableExtra::kable_styling(full_width=T)
```

In addition, a result of hierarchical clustering is also shown below for
visualization to get intuition how the features are grouped and how the
connection constructs the VNN model architecture.

```{python figure-1, echo=FALSE, fig.cap='Ontology by hierarchical clustering'}
from matplotlib import pyplot as plt
from scipy.cluster.hierarchy import dendrogram

def plot_dendrogram(model, **kwargs):
  # Create linkage matrix and then plot the dendrogram
  
  # Create the counts of samples under each node
  counts = np.zeros(model.children_.shape[0])
  n_samples = len(model.labels_)
  for i, merge in enumerate(model.children_):
    current_count = 0
    for child_idx in merge:
      if child_idx < n_samples:
        current_count += 1  # leaf node
      else:
        current_count += counts[child_idx - n_samples]
    counts[i] = current_count
  
  linkage_matrix = np.column_stack([model.children_, model.distances_,
                                    counts]).astype(float)
  
  # Plot the corresponding dendrogram
  dendrogram(linkage_matrix, **kwargs)

plt.title('Hierarchical Clustering Dendrogram')
plot_dendrogram(input['hierarchy'])
```

```{python include=FALSE}
hierarchy=pd.DataFrame.from_dict({
    'label':input['hierarchy'].labels_
    ,'feature':input['value'].columns.values[input['hierarchy'].labels_]
  })
```

```{r echo=FALSE}
py$hierarchy %>%
  knitr::kable(format='html',caption='Ontology data frame') %>%
  kableExtra::kable_styling(full_width=T)
```


# Create TidySet

Create a TidySet using this code.

```{r Compile input to a TidySet, eval=FALSE, echo=TRUE}
tidy_set=TidySet.compile(
    value=input['value']
    ,outcome=input['outcome']
    ,similarity=input['similarity']
    ,mapping=input['mapping']
    ,ontology=input['ontology']
  )
```
```{python include=FALSE}
tidy_set=TidySet.read('quick-start-py/tidy_set_py.ts.tar.gz')
```

TidySet is an ExpressionSet with three tables. Instance-feature
value and outcome pandas data frame are compiled as a phenotype pandas data
frame with rows for instances and columns for features and outcome.

```{python TidySet, echo=TRUE}
tidy_set.desc()
```

Instance-feature value and feature three-dimensional mapping pandas data frame
are compiled as an expression two-dimensional array with rows for positions of
features and columns for instances. The mapping, similarity, and ontology
pandas data frame are compiled as a feature pandas data frame with rows for
positions of features and columns for feature names and ontological relations.
For easier access, the similarity pandas data frame, ontomap four-dimensional
numpy array, ontotype dictionary of pandas data frame, and ontology pandas
data frame are included in experiment notes that can be called using function
of notes.

```{python, include=FALSE}
pdata=pData(tidy_set)
fdata=fData(tidy_set)
adata=exprs(tidy_set)
```

```{r echo=FALSE}
list(
    `Phenotype data frame`=py$pdata %>% dim
    ,`Feature data frame`=py$fdata %>% dim
    ,`Expression matrix`=py$adata %>% dim
  ) %>%
  do.call(rbind,.) %>%
  as.data.frame() %>%
  rename_all(function(x)str_replace_all(x,'V','dimension ')) %>%
  knitr::kable(format='html',caption='Dimensions of three tables') %>%
  kableExtra::kable_styling(full_width=T)
```

Recall experiment notes such similarity, ontomap, ontotype, and ontology using
this code.

```{python Recall experiment notes, eval=FALSE, echo=TRUE}
# Recall a similarity matrix
notes(tidy_set.experimentData)['similarity']

# Recall an ontomap four-dimensional array
notes(tidy_set.experimentData)['ontomap']

# Recall an ontotype list of two-dimensional matrices
notes(tidy_set.experimentData)['ontotype']

# Recall an ontology data frame
notes(tidy_set.experimentData)['ontology']
```

# Save or load a TidySet

Use this code to save a TidySet by writing a .ts.tar.gz file containing
exprs.csv, pData.csv, fData.csv, similarity.csv, ontology.csv, and others.txt.

```{python Save a TidySet, eval=FALSE, echo=TRUE}
TidySet.write(tidy_set,'quick-start-py/tidy_set_py')
```

Function of TidySet.read can read this file back to a TidySet. Use
this code to load a TidySet by reading a .ts.tar.gz file.

```{python Load a TidySet, eval=FALSE, echo=TRUE}
tidy_set=TidySet.read('quick-start-py/tidy_set_py.ts.tar.gz')
```


# Create ontonet

Let's create a function that generate a Keras Convolutional Neural Network (CNN)
model with a specific layer architecture for each path in the hierarchy of the
given ontology. The model architecture can be saved to JSON for later use by
specifying the file path; otherwise (by let it NULL), no JSON will be created.

```{python Create ontonet generator function, eval=FALSE, echo=TRUE}
ontonet=generator.ontonet(tidy_set,path='quick-start-py/ontonet_py')
```
```{python include=FALSE}
json_file=open('quick-start-py/ontonet_py.json','r')
ontonet=json_file.read()
json_file.close()
ontonet=model_from_json(ontonet)
```


# Set up hyperparameters

The model is compiled with stochastic gradient decent (SGD)
using learning rate (LR) of 2^-6 and momentum of 0.9. The loss function is mean
squared error (MSE) with weight of 1 for main output and 0.3 fir auxiliary
output. The evaluation metric is accuracy.

The LR will be reduced by factor of 0.1 at iteration 30, 60, and 80 (but with
0-based index). Early stopping will also happen if validation loss does not
decrease >0.001 after 30 iterations. The best weight at minimum validation loss
will be applied.

```{python Set up hyperparameters with callbacks, echo=TRUE}
ontonet.compile(
    optimizer=keras.optimizers.SGD(
      learning_rate=2**-6
      ,momentum=0.9
    )
    ,loss='mean_squared_error'
    ,loss_weights=np.repeat(0.3,len(ontonet.outputs)-1).tolist()+[1]
    ,metrics=['accuracy']
  )

def cb_lr_reduction(epoch,lr):
  lr_factor=0.1
  if epoch in [29,59,79]: lr=lr*lr_factor
  return lr
cb_lr_reduction=keras.callbacks.LearningRateScheduler(cb_lr_reduction)

cb_early_stopping=keras.callbacks.EarlyStopping(
    monitor='val_loss'
    ,mode='min'
    ,min_delta=0.001
    ,patience=30
    ,restore_best_weights=True
  )
```

# Data partition

We hold out ~20% dataset for test set, while ~20% of the remaining will be a
validation set. Training set will use the 80% of the remaining instances.

```{python Randomize sample for test set then validation and train sets, echo=FALSE}
np.random.seed(33)
index=np.random.choice(
    np.arange(exprs(tidy_set).shape[1])
    ,size=exprs(tidy_set).shape[1]
    ,replace=False
  ).tolist()

test_i=np.random.choice(
    index
    ,size=np.round(0.2*len(index)).astype(int)
    ,replace=False
  ).tolist()

val_i=[]
for i in index:
  if not i in [index[j] for j in test_i]:
    val_i.append(i)
val_i=np.random.choice(
    val_i
    ,size=np.round(0.2*len(val_i)).astype(int)
    ,replace=False
  ).tolist()

train_i=[]
for i in index:
  if not i in [index[j] for j in (test_i+val_i)]:
    train_i.append(i)
```

# Model training

We use this code to train the model. The sample generator for ontoarray will
take 32 samples for each batch. This step is repeated until all samples of
training set are used per epoch, up to 100 epochs, but can be stopped earlier.
For each epoch, validation performance is also measured with the same batch
size.

```{python Train the model, eval=FALSE, echo=TRUE}
history=ontonet.fit_generator(
    generator=generator.ontoarray(
        tidy_set
        ,[index[i] for i in train_i]
        ,batch_size=32
      )
    ,steps_per_epoch=math.ceil(len(train_i)/32)
    ,validation_data=generator.ontoarray(
        tidy_set
        ,[index[i] for i in val_i]
        ,batch_size=32
      )
    ,validation_steps=math.ceil(len(val_i)/32)
    ,epochs=100
    ,callbacks=[cb_lr_reduction,cb_early_stopping]
    ,verbose=1
  )
```
```{python include=FALSE}
ontonet.load_weights('quick-start-py/ontonet_py.h5')

with open('quick-start-py/history_py.pkl','rb') as f:
  history=pickle.load(f)
```

Here below is the training result. We can estimate the iteration of which the
weights are optimum for prediction.

```{r figure-2, echo=FALSE, fig.cap='Plot training and validation losses'}
py$history %>%
  .[c('loss','val_loss')] %>%
  lapply(unlist) %>%
  as.data.frame() %>%
  mutate(iteration=seq(nrow(.))) %>%
  gather(metric,value,-iteration) %>%
  qplot(
    iteration,value,color=metric,data=.
    ,geom='smooth',method='loess',formula=y~x,se=F
  ) +
  theme_minimal()
```

# Model evaluation

The test set is used for model evaluation by bootstrapping. The sample generator
for ontoarray will take 32 samples for each batch. This step is repeated until
all samples of training set are used per bootstrap, until 30 times.

```{python Evaluate model on test set, eval=FALSE, echo=TRUE}
np.random.seed(33)
evaluation={}
for i in np.arange(30):
  test_i_boot=np.random.choice(
    test_i
    ,size=len(test_i)
    ,replace=True
  ).tolist()
  evaluation[i]=ontonet.evaluate_generator(
    generator=generator.ontoarray(
        tidy_set
        ,[index[i] for i in test_i_boot]
        ,batch_size=32
      )
    ,steps=math.ceil(len(test_i)/32)
  )
```
```{python include=FALSE}
with open('quick-start-py/evaluation_py.pkl','rb') as f:
  evaluation=pickle.load(f)
```

The point and interval (95% CI) estimates of accuracy can be computed by
the bootstrapping.

```{python Compute point and interval estimates of accuracy, include=FALSE}
I=[]
for i in history.keys():
  if 'val' in i:
    I.append(re.sub('val','test',i))

Y=pd.DataFrame()
for i in evaluation.keys():
  Y=Y.append(
      pd.DataFrame.from_dict({'boot':i,'metric':I,'result':evaluation[i]})
    )

Z=pd.DataFrame()
for i in I:
  K=Y.result[Y.metric==i].to_list()
  Z=Z.append(
      pd.DataFrame.from_dict({
        'mean':[np.mean(K)]
        ,'lb':[np.mean(K)-1.96*np.std(K)/np.sqrt(30)]
        ,'ub':[np.mean(K)+1.96*np.std(K)/np.sqrt(30)]
      })
    )
Z=Z.reset_index(inplace=False)
del Z['index']
Z['metric']=I
results=Z
del i, I, Y, Z
```

Therefore, the predictive performance of this model can be
generalized for future, unobserved samples.

```{r Show point and interval estimates of root accuracy, echo=FALSE}
py$results %>%
  select(metric,everything()) %>%
  mutate(metric=str_remove_all(metric,'test_')) %>%
  filter(metric=='root_accuracy') %>%
  knitr::kable(
    format='html'
    ,caption='Accuracy estimates (95% CI) on test set'
  ) %>%
  kableExtra::kable_styling(full_width=T)
```

# Session info

```{python Session info}
from sinfo import sinfo
sinfo()
```
